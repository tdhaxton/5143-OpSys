import os, sys
sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))

#from schedulers.base import Scheduler
#from schedulers.rr import RoundRobinScheduler
import json
# import utils
from process import Process
from utils.clock import Clock
from schedulers import Scheduler, RoundRobinScheduler, ShortestJobFirst


# ---------------------------------------
# Load JSON into Process objects
# ---------------------------------------
def load_processes_from_json(filename="generated_processes.json", limit=None):
    """Load processes from a JSON file into Process instances
    Args:
        filename: path to the JSON file
        limit: if set, only load this many processes
    Returns:
        list of Process instances
    Raises:
        FileNotFoundError if the file does not exist
    """

    # If limit is set, only load that many processes
    with open(filename) as f:
        data = json.load(f)

    processes = []

    # If limit is None or greater than available, use all
    if limit is None or limit > len(data):
        limit = len(data)

    # :limit slices the list of processes loaded from the JSON file to only include
    # the first 'limit' number of processes.
    # This is useful for testing or running simulations with a smaller subset of processes.
    for p in data[:limit]:

        # Create a list of bursts in the expected format for Process
        # [{"cpu": X}, {"io": {"type": T, "duration": D}}, ...]
        bursts = []

        # Iterate over each burst in the process's burst list
        # and append to bursts list in the correct format
        for b in p["bursts"]:
            if "cpu" in b:
                # format {"cpu": X}
                bursts.append({"cpu": b["cpu"]})

            elif "io" in b:
                # format {"io": {"type": T, "duration": D}}
                bursts.append(
                    {"io": {"type": b["io"]["type"], "duration": b["io"]["duration"]}}
                )

        proc = Process(
            pid=p["pid"],
            bursts=bursts,
            priority=p["priority"],
            arrival_time=p["arrival_time"]
        )
        processes.append(proc)

    return processes


def parse_value(value):
    """
    Try to convert string to appropriate type since everything read in from command line is a string
    Args:
        value: string value to parse
    Returns:
        value converted to bool, int, float, or original string
    """
    # Try boolean
    if value.lower() in ("true", "false"):
        return value.lower() == "true"
    # Try int
    try:
        return int(value)
    except ValueError:
        pass
    # Try float
    try:
        return float(value)
    except ValueError:
        pass
    # Give up, return string
    return value


def argParse():
    """Parse command line arguments into a dictionary
    Returns:
        dict of argument names to values
    """
    kwargs = {}
    for arg in sys.argv[1:]:
        if "=" in arg:
            key, value = arg.split("=", 1)
            kwargs[key] = parse_value(value)
    return kwargs


# ---------------------------------------
# Example usage
# ---------------------------------------
if __name__ == "__main__":
    # Parse command line arguments
    args = argParse()

    # Get parameters if they exist, else use defaults
    # file_num is used to load different process files and save different timeline files
    file_num = args.get("file_num", 1)

    # Limit is used to restrict the number of processes loaded
    limit = args.get("limit", None)

    # Number of CPUs and IO devices
    cpus = args.get("cpus", 1)
    ios = args.get("ios", 1)
    
    sceduler = args.get("sched", "fcfs")
    
    # rr=true to use Round Robin
    #use_rr = str(args.get("rr", False)).lower() == "true"
    # quantum size (default 4)
    quantum = args.get("quantum", 4)

    # Run the simulation
    clock = Clock()
    print(f"\n=== Simulation with {cpus} CPU(s) and {ios} IO device(s) ===")

    # Load processes from JSON file
    processes = load_processes_from_json(
        f"./job_jsons/process_file_{str(file_num).zfill(4)}.json", limit=limit
    )

    # Initialize scheduler
    if sceduler.lower() == "rr":
        print(f"Using Round Robin with quantum={quantum}")
        sched = RoundRobinScheduler(
            num_cpus=cpus,
            num_ios=ios,
            verbose=False,
            processes=processes,
            quantum=quantum
        )
        
    elif sceduler.lower() == "sjf":
        print("Using Shortest Job First")
        sched = ShortestJobFirst(
            num_cpus=cpus,
            num_ios=ios,
            verbose=False,
            processes=processes
        )
        
    else:
        print("Using First come First Serve")
        sched = Scheduler(
            num_cpus=cpus,
            num_ios=ios,
            verbose=False,
            processes=processes
        )

    # Run the scheduler
    sched.run()

    # Print final log and stats
    print("\n--- Final Log ---")
    print(sched.timeline())
    print(f"\nTime elapsed: {sched.clock.now() - 1}")
    print(f"Finished: {[p.pid for p in sched.finished]}")

    # Export structured logs
    sched.export_json(f"./timelines/timeline{str(file_num).zfill(4)}.json")
    sched.export_csv(f"./timelines/timeline{str(file_num).zfill(4)}.csv")
    clock.reset()
